\documentclass[12pt, a4paper]{article}
\usepackage[UTF8, fontset=fandol]{ctex}
\usepackage{sectsty}
\usepackage{url}
\usepackage{geometry}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{cite}
\usepackage{setspace}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{pgffor}
\usepackage{caption} % 在导言区添加
% 设置页面边距
\geometry{a4paper, top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm}

% 设置行间距
\onehalfspacing

% 设置超链接样式
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    urlcolor=blue,
    citecolor=black
}

% 设置代码块样式
\lstset{
     basicstyle=\ttfamily\small,
     keywordstyle=\color{blue},
     commentstyle=\color{gray},
     stringstyle=\color{red},
     breaklines=true,
     numbers=left,
     numberstyle=\tiny,
     frame=single,
     language=Python % 可根据需要更换为 C, C++, Java 等
   }


\title{GAN系列模型实验报告}
\author{高家璇 3023244275}
\begin{document}



\maketitle
\begin{center}
    \includegraphics[width=0.8\textwidth]{/Users/slkgaw/Proj/GANS/visual/BigGAN/512x512_random/random_samples_512_004.jpg}
\end{center}
\begin{center}
\section*{摘要}
\end{center}

在 AIGC 如此火爆的今天，了解生成模型的鼻祖 GAN (arXiv:1406.2661)是很有必要的。
GAN 是深度学习花书的作者 Ian Goodfellow 在 2014年的一篇工作，引发了一股 GAN 生模型的浪潮，
这股生成模型的浪潮一直持续到现在的 Diffusion 系列。

如今 GPT 如此发达，大部分报告内容都可以由 AI 生成。
所以本报告不会花特别多的篇幅来介绍模型的理论架构或者是其他死板的内容。为了实现本实验的终极目的：帮助学生加深对 GAN 模型的架构和训练的理解。
\textbf{因此此报告将花费大规模篇幅来重点讨论 GAN 系列模型在给定下游任务时的【训练细节与训练技巧】。}

本实验实现了：
1、GAN 在 MNIST 数据集上的训练和推理。
2、在不同数据集上训练了多个数亿参数规模的 CGAN。
3、200+ 小时训练时长，60+ 训练日志文件，1000+ 样本和损失可视化。


本报告探讨了：
1、学习率调度、正则化、模型保存与加载、损失日志与阶段可视化等实用的训练技巧
2、模型训练中的张量数据并行、分布式与混合精度训练策略
3、模型训练中的数据增强与预处理技巧，以及超参数分析
4、GAN 在建模复杂数据分布时的模式坍塌问题



本实验全部代码和构建记录：\url{https://github.com/slkhms777/GANS}

生成模型综述与主流模型代码：\url{https://github.com/slkhms777/AIGC}



% 正文
\newpage
\begin{center}
\section*{引言}
\end{center}

生成对抗网络（Generative Adversarial Networks, GANs）自 2014 年由 Goodfellow 等人提出以来，已成为深度学习领域最具影响力的创新之一。GAN 通过生成器与判别器的对抗性训练，使生成器能够逐步提升生成样本的质量，最终达到以假乱真的效果。

然而，原始 GAN 在实际应用中常常面临训练不稳定、模式坍塌（mode collapse）、梯度消失等问题。为了解决这些挑战，研究者们提出了多种改进模型，其中较为典型的包括 Wasserstein GAN（WGAN）和条件生成对抗网络（Conditional GAN, CGAN）。

\textbf{WGAN（Wasserstein GAN）} 针对训练不稳定和模式坍塌问题进行了有效改进。其核心思想是采用 Wasserstein 距离（又称 Earth Mover 距离）来衡量真实分布与生成分布之间的差异，替代了原始 GAN 中的 JS 散度。WGAN 的主要特点包括：

1. 以 Wasserstein 距离为损失函数，提升训练稳定性；

2. 判别器（Critic）输出实数值而非概率；

3. 通过权重裁剪（weight clipping）满足 Lipschitz 连续性约束；

4. 损失函数与生成样本质量正相关，便于训练过程监控。

在此基础上，\textbf{WGAN-GP（WGAN with Gradient Penalty）} 进一步用梯度惩罚（gradient penalty）替代权重裁剪，带来了更好的 Lipschitz 约束，避免了梯度消失或爆炸等问题，使训练更加稳定，生成质量进一步提升。

\textbf{CGAN（Conditional GAN）} 则在 GAN 框架中引入了条件信息，使得生成过程可控。与原始 GAN 的无条件生成不同，CGAN 能够根据输入的类别标签等条件生成特定类型的样本。其核心思想包括：

1. 生成器和判别器均以条件信息 $c$ 作为输入；

2. 生成器 $G(z, c)$ 以噪声 $z$ 和条件 $c$ 生成样本；

3. 判别器 $D(x, c)$ 判断样本 $x$ 在条件 $c$ 下的真实性；

4. 支持按需生成特定类别样本，提升生成多样性和训练稳定性。

\textbf{BigGAN} 是 Google 于 2018 年提出的大规模高分辨率图像生成模型，在 ImageNet 等数据集上取得了突破性成果。BigGAN 通过扩大模型规模、引入自注意力机制（Self-Attention）、谱归一化（Spectral Normalization）、类别条件 BatchNorm 以及截断技巧（Truncation Trick）等方法，极大提升了生成图像的质量和多样性。其主要创新点包括：

1. 大规模训练（更大的 batch size 和更深的网络结构）；

2. 在生成器和判别器中引入 Self-Attention 机制；

3. 谱归一化稳定训练过程；

4. 类别条件 BatchNorm 增强类别信息利用；

5. 截断技巧提升推理阶段生成质量。

BigGAN 的成功验证了“规模即力量”的理念，为后续如 StyleGAN、DALL-E 等更大规模生成模型的发展奠定了基础。

本实验以 MNIST、CIFAR-10、Animal-Faces 及 ImageNet-1k 等数据集为基础，重点探讨了上述模型的训练技巧及生成结果的可解释性分析。
% 目录页
\newpage
\tableofcontents

\newpage
\section{任务一，二：GAN，WGAN，CGAN 在 MNIST 上的训练以及推理}
\subsection{实验设置与方法}
\subsubsection{实验设置}
\begin{itemize}
    \item 模型架构：简单的MLP网络作为生成器和判别器
    \item 数据集：MNIST 手写数字数据集
    \item 硬件：2张 NVIDIA RTX 3090 GPU 
\end{itemize}

\subsubsection{实验方法}
在mnist数据集上，训练GAN，WGAN。通过随机采样噪声向量生成手写数字图像。
CGAN略有不同，CGAN支持类别收入，因此可以指定生成特定类别的手写数字。

\subsubsection{代码示例（仅给出GAN的代码示例）}

\begin{lstlisting}[language=Python, caption=GAN 训练主循环示例]
class Generator(nn.Module):
    def __init__(self, img_size, noise_size, num_hiddens, out_channels=1):
        super().__init__()
        self.img_size = img_size
        self.out_channels = out_channels
        self.fc1 = nn.Linear(noise_size, num_hiddens)
        self.bn1 = nn.BatchNorm1d(num_hiddens)
        self.fc2 = nn.Linear(num_hiddens, num_hiddens)
        self.bn2 = nn.BatchNorm1d(num_hiddens)
        self.fc3 = nn.Linear(num_hiddens, img_size * img_size * out_channels)
        self.relu = nn.LeakyReLU()
        self.tanh = nn.Tanh()

    def forward(self, noise):
        x = self.relu(self.bn1(self.fc1(noise)))
        x = self.relu(self.bn2(self.fc2(x)))
        x = self.tanh(self.fc3(x))
        x = x.view(-1, self.out_channels, self.img_size, self.img_size)
        return x

class Discriminator(nn.Module):
    def __init__(self, img_size, num_hiddens, in_channels=1):
        super().__init__()
        self.flt = nn.Flatten()
        self.fc1 = nn.Linear(img_size * img_size * in_channels, num_hiddens)
        self.dropout1 = nn.Dropout(0.3)
        self.fc2 = nn.Linear(num_hiddens, num_hiddens)
        self.dropout2 = nn.Dropout(0.3)
        self.fc3 = nn.Linear(num_hiddens, 1)
        self.relu = nn.LeakyReLU()
    def forward(self, image):
        x = self.flt(image)
        x = self.relu(self.fc1(x))
        x = self.dropout1(x)
        x = self.relu(self.fc2(x))
        x = self.dropout2(x)
        x = self.fc3(x)
        return x

for epoch in range(num_epochs):
    for real_imgs, _ in dataloader:
        # 判别器训练
        生成噪声 noise
        用生成器生成假图像 fake_imgs = Generator(noise)
        判别器判别真实图片 outputs_real = Discriminator(real_imgs)
        判别器判别假图片 outputs_fake = Discriminator(fake_imgs.detach())
        计算判别器损失 loss_d = criterion(outputs_real, 1) + criterion(outputs_fake, 0)
        判别器反向传播和优化

        # 生成器训练
        生成新的噪声 noise
        用生成器生成假图像 fake_imgs = Generator(noise)
        判别器判别假图片 outputs = Discriminator(fake_imgs)
        计算生成器损失 loss_g = criterion(outputs, 1)
        生成器反向传播和优化

    记录并打印每个epoch的损失，定期保存模型权重，定期生成样本图片
\end{lstlisting}

\subsection{训练细节与训练技巧}
\subsubsection{正则化}
在一般的深度学习过程中，正则化是一个非常重要的环节，因为如果确实有效的正则化，模型很容易过拟合到数据集上，导致
模型的泛化性大大降低。常见的正则化有dropout和weight decay，二者虽然实现方式不同，但本质上都是防止部分神经元
在整个模型中dominate。对于weight decay，采用限制一部分神经元的权重大小的方式来防止过拟合。而dropout则直接
丢弃部分神经元来防止过拟合，二者在原理上有异曲同工。

但是针对任务一，二，正则化的作用往往不那么明显。由于mnist数据集本身的特性，相同数字的不同形态差异往往非常小，
正如本实验指导ppt中所展示的像素分布热力图，同一个数字的分布非常集中。因此从生成质量这个角度出发，我们甚至有一点
希望模型能够过拟合，不去限制神经元的dominate。举个例子，数字8显著的特征之一就是两个圈圈交汇处，形如“x”，因此
这个特征基本可以作为数字8的“身份证”，我们希望模型能够记住这个“身份证”，至于上下两个圈，瘦一点，胖一点，宽一点，
扁一点……都不影响数字8的整体样貌。因此我在模型设计时采用了比较小的丢弃率，而且仅对判别器使用，希望判别器稍微放宽难度。

防止过拟合是正则化之于生成模型的第一作用，至于正则化之于生成模型第二作用，我想大抵是保证生成样本的多样性。
就好比数字1有笔直的形态，也有斜体的形态，我们当然希望模型在生成数字1的时候在能够识别出的前提下，还能够有
各种角度的倾斜，以达到多样性。如下图所示

\vspace{1cm}


\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{/Users/slkgaw/Proj/GANS/visual/CGAN/cgan_sample_epoch_200.png}
\end{figure}

\newpage
\subsubsection{超参数调整}
GAN系列算是对超参数比较敏感的一系列模型了。首先，如果超参数调整不当，很容易导致生成器和判别器的参数量不match，
如果相比之下判别器的参数量过多，则会过于严苛，会促进生成器作弊，只生成一小部分种类，从而大幅降低生成图片的多样性。
如果相比之下判别器的参数量过少，则会过于放养，会促进生成器偷懒，只生成大致轮廓即可，从而大幅降低生成图片的质量。
而这仅仅只是从模型参数量的角度的定性分析。在实际训练过程中，不同的trick对模型训练有不同的影响。
超参数选择具体如下：
\begin{itemize}
    \item \texttt{batch\_size = 256}
    \item \texttt{noise\_size = 64}
    \item \texttt{num\_hiddens = 512}
    \item \texttt{num\_epochs = 200}
    \item \texttt{learning\_rate = 0.0002}
\end{itemize}

\vspace{0.5cm}
噪声选择64是因为mnist数据本身不算复杂，64足矣，num\_hiddens选择512则是想让模型尽可能多地囊括数据细节和多样性分布。
这两个超参数的影响也比较直观，不过多赘述。

第一个值得探讨的超参数是batch大小，为什么在显存很充足的情况下仍然选择256的学习率？为什么不直接上4096的batch大小？
其实256的batch大小不算很小，只不过是mnist数据图片size很小可以稍微翻个倍。选择不吃满显存也是mnist数据集的原因。
经实验发现，batch选择过大虽然可以明显加速训练，但是会导致训练非常不稳定，大bacth带来的大梯度对小数据集会带来很大的
震荡。最终容易对生成的图片产生影响，如产生噪点和部分细节缺失。而batch选择太小则会对数据噪声敏感，同样会带来生成图片
质量下降的问题。

第二个值得讨论的超参数是学习率和num\_epochs的组合选择。在本实验中为了训练过程流程，生成图片的质量稳定，选择了小学习率
+多epoch的训练策略。从定性的角度上分析，多epoch表示学的久，小学习率表示学的细。虽说小学习率带来更好的学习效果
是一种经验主义，但还是可以从一些数学的角度分析得来的。所谓的梯度下降算法就是一个最优化问题。在解空间中，维度很高导致
很难用显式的方式表现，但可以类比三维空间。三维空间的最优化问题其实就是一座一座山丘，一座座山丘也被称作梯度景观。
而在高维空间中，梯度景观是十分复杂的，如果学习率偏大，则会导致在最优点的“坑”附近反复横跳，无法深入下一阶段的特征学习，
这正是学习率选择较小值的理论依据。同时也正因为这种梯度景观的复杂性和层次性，也引出了一系列学习率技巧，如最典型的schedule方案
（在后续分析中有提及）能够促使模型在早期epoch学习大致特征，而在中后期逐渐学习细节特征。


\subsubsection{单机多卡并行}
深度学习的发展离不开算力的改进，因此本实验选择单机双卡来进行张量数据并行。
以下是单机多卡的代码示例:
\begin{lstlisting}[language=Python, caption=GAN 训练主循环示例]
# 1. 构建模型
generator = Generator(...)
discriminator = Discriminator(...)

# 2. 多卡包装
if GPU数量 > 1:
    generator = DataParallel(generator)
    discriminator = DataParallel(discriminator)

# 3. 训练和保存权重时，获取原始模型
if isinstance(generator, DataParallel):
    generator_module = generator.module
    discriminator_module = discriminator.module
else:
    generator_module = generator
    discriminator_module = discriminator

# 4. 保存模型
torch.save: generator_module.state_dict()
torch.save: discriminator_module.state_dict()

# 5. 加载模型
if isinstance(generator, DataParallel):
    generator.module.load_state_dict(...)
else:
    generator.load_state_dict(...)
\end{lstlisting}

需要注意的是如果要保存、加载模型参数，或者直接访问模型的成员变量和方法等，必须要用.module属性来访问。
但是在前向和推理时，则反而不要用.module，这样可以保证张量数据自动分配到多卡从而进行并行。
其次，模型需要先 to(device) 再 DataParallel，否则多卡时参数可能不在同一设备上，并且多卡训练时
 batch\_size 要足够大，否则每卡的数据太少，效率低下。

\newpage
\subsubsection{多epoch + 学习率schedule}
在本实验中为了训练过程流程，生成图片的质量稳定，选择了多epoch + 学习率schedule的训练策略。
从定性的角度上分析，多epoch表示学的久，小学习率表示学的细，学习率schedule表示学得深。由于mnist数据集本身的特性
不必用非常复杂的schedule技巧，因此在任务一、二中仅使用普通的等比缩小策略，代码如下：
\begin{lstlisting}
# 1. 初始化
定义 Generator 和 Discriminator
如多GPU则用 DataParallel 包装
定义优化器 optimizer_g, optimizer_d
定义学习率调度器 scheduler_g, scheduler_d
定义损失函数 criterion

# 2. 优化器与学习率调度
optimizer_g = Adam(generator参数)
optimizer_d = Adam(discriminator参数)
scheduler_g = StepLR(optimizer_g, 每50epoch学习率*0.5)
scheduler_d = StepLR(optimizer_d, 每50epoch学习率*0.5)

# 3. 训练循环
for epoch in num_epochs:
    for real_imgs in dataloader:
        # 判别器训练
        生成噪声 noise
        用 generator 生成 fake_imgs
        判别器分别判别 real_imgs 和 fake_imgs
        计算判别器损失 loss_d
        优化判别器

        # 生成器训练
        生成噪声 noise
        用 generator 生成 fake_imgs
        判别器判别 fake_imgs
        计算生成器损失 loss_g
        优化生成器

    scheduler_g.step()
    scheduler_d.step()
    定期保存模型权重与生成样本
    记录损失

\end{lstlisting}


\subsubsection{模型保存与可视化}

多epoch的训练必须要有保存模型的习惯，一是后续可以直接加载历史模型参数进行分析，二是防止训练意外终止造成成本损失。
在本实验中，数据集很简单因此只保存模型。但在后续的复杂数据集的情况下，应该同时保存优化器的配置，一是在训练不充分
不理想时便于接续训练，二是可以后期查看历史优化器的状态来分析训练过程的现象。

以下是示例代码和文件结构示例：

\begin{lstlisting}
# 训练过程中保存模型
每隔20个epoch:
    保存 generator_module 的参数到 checkpoint_dir/generator_epoch{epoch}.pth
    保存 discriminator_module 的参数到 checkpoint_dir/discriminator_epoch{epoch}.pth

# 训练结束后保存损失
保存 g_losses 和 d_losses 到 txt 文件
保存 g_losses 和 d_losses 到 csv 文件（可选）
绘制损失曲线并保存为 png 图片

# 生成可视化样本
for epoch in [20, 40, ..., num_epochs]:
    如果存在 generator_epoch{epoch}.pth 权重文件:
        加载权重到 generator
        用 generator 生成100张图片
        保存生成图片到 visual/GAN/gan_sample_epoch_{epoch}.png
\end{lstlisting}

\begin{figure}[htbp]
    \centering
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{/Users/slkgaw/Proj/GANS/visual/111.png}
        \caption{示例图片一：日志结构}
        \label{fig:img111}
    \end{minipage}
    \hspace{0.04\textwidth}
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{/Users/slkgaw/Proj/GANS/visual/222.png}
        \caption{示例图片二：可视化结构}
        \label{fig:img222}
    \end{minipage}
\end{figure}

\newpage
\subsubsection{插值分析}
为了判断生成图片的质量和多样性，其实有FID和IS这种指标，甚至可以直接肉眼观察视觉效果。
但更形象且有数理依据的方法就是插值分析。具体方法如下（以CGAN为例），选定两组（c, z）对，
并在这两对中进行线性、球面插值。以下是在训练完成时进行插值可视化的结果。
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{/Users/slkgaw/Proj/GANS/visual/interpolation/res/0_to_1_interp.png}
    \caption{0 到 1 的插值}
    \label{fig:interp01}
    \vspace{0.8cm} % 间隔
    \includegraphics[width=0.85\textwidth]{/Users/slkgaw/Proj/GANS/visual/interpolation/res/1_to_2_interp.png}
    \caption{1 到 2 的插值}
    \label{fig:interp12}
    \vspace{0.8cm} % 间隔
    \includegraphics[width=0.85\textwidth]{/Users/slkgaw/Proj/GANS/visual/interpolation/res/2_to_3_interp.png}
    \caption{2 到 3 的插值}
    \label{fig:interp23}
    \vspace{0.8cm} % 间隔
    \includegraphics[width=0.85\textwidth]{/Users/slkgaw/Proj/GANS/visual/interpolation/res/8_to_9_interp.png}
    \caption{8 到 9 的插值}
    \label{fig:interp89}
\end{figure}
从插值可视化的结果可以发现数字在特征过度的时候非常平滑，基本可以证明各个类别的数字在空间中是均匀离散分布的。
为了做比较，以下展示训练不充分时的插值可视化结果，这可以作为各个类别在空间上仍未被完全分开的证据。
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{/Users/slkgaw/Proj/GANS/visual/interpolation/test1/4_to_5_interp.png}
    \caption{4 到 5 的插值}
    \label{fig:interp45}
    \vspace{0.8cm} % 间隔
    \includegraphics[width=0.85\textwidth]{/Users/slkgaw/Proj/GANS/visual/interpolation/test1/5_to_6_interp.png}
    \caption{5 到 6 的插值}
    \label{fig:interp56}
    \vspace{0.8cm} % 间隔
    \includegraphics[width=0.85\textwidth]{/Users/slkgaw/Proj/GANS/visual/interpolation/test1/6_to_7_interp.png}
    \caption{6 到 7 的插值}
    \label{fig:interp67}

\end{figure}

\subsection{实验结果与分析}
\subsubsection{GAN和CGAN}
\begin{figure}[htbp]
    \centering
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{/Users/slkgaw/Proj/GANS/visual/GAN/gan_sample_epoch_200.png}
        \caption{GAN在200轮训练后的生成效果}
    \end{minipage}
    \hspace{0.04\textwidth}
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{/Users/slkgaw/Proj/GANS/visual/CGAN/cgan_sample_epoch_200.png}
        \caption{CGAN在200轮训练后的生成效果}
    \end{minipage}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{/Users/slkgaw/Proj/GANS/Logs/loss_gan/gan_loss_curve.png}
    \caption{GAN损失曲线}
\end{figure}
\clearpage
\begin{figure}[htbp]
    \includegraphics[width=\textwidth]{/Users/slkgaw/Proj/GANS/Logs/loss_cgan/cgan_loss_curve.png}
    \caption{CGAN损失曲线}
\end{figure}

从生成的图片来分析，可以发现 在多epoch + 小学习率 + 学习率schedule的训练策略下，GAN和CGAN生成图片的结果基本符合预期，
并且都展示了不错的多样性。
值得探讨的一点是，在模型大小，训练策略差不多的情况下CGAN的效果会比GAN的效果稍微好一些，具体体现在数字的
笔画更清晰，噪点更少。
这也正是CGAN的意义所在，C带标conditional，CGAN不仅是支持按类别生成，更重要的是类别能够知道模型进行训练
并知道模型生成。可以类比于Improved DDPM中使用的classifier guidance，这里的conditional相当于是一个ligth版本的
cls guidance。GAN的图片有不少噪点的原因，很大一部分程度是由于确实类别指导，在生成图像过程中有些拖泥带水，会附带小部分
其他类别的杂糅信息。

从损失曲线来看，GAN和CGAN基本都在30个epoch就在mnist数据集上达到了比较不错的效果。
值得探讨的是生成器和判别器的博弈关系，二者的loss曲线震荡的方向基本相反，符合“对抗”训练的过程。
而且因为有了类别指导，CGAN的收敛方向更准确，收敛速度更快。另一个可以探讨的点是，尽管在中后期生成器的损失有所上升，判别器的损失下降，
但是生成的图片的质量依然还在有上升的趋势，这也正是GAN的核心思想之一：纳什均衡。判别器的损失下降，表示判别器学到了更好的特征，有了更
严格的判定。因此促使生成器进一步提升。

\vspace{1cm}
完整的生成图片的样本随epoch的变化在附录


\clearpage
\subsubsection{WGAN和WGAN-GP}

\subsection{实验结果与分析}

\begin{figure}[htbp]
    \centering
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{/Users/slkgaw/Proj/GANS/visual/WGAN/Wgan_sample_epoch_200.png}
        \caption{WGAN在200轮训练后的生成效果}
    \end{minipage}
    \hspace{0.04\textwidth}
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{/Users/slkgaw/Proj/GANS/visual/WGAN-GP/wgan_gp_sample_epoch_200.png}
        \caption{WGAN-GP在200轮训练后的生成效果}
    \end{minipage}
\end{figure}

\vspace{1cm}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{/Users/slkgaw/Proj/GANS/Logs/loss_wgan/wgan_loss_curve.png}
    \caption{WGAN损失曲线}
\end{figure}
\clearpage
\begin{figure}[htbp]
    \includegraphics[width=\textwidth]{/Users/slkgaw/Proj/GANS/Logs/loss_wgan_gp/wgan_gp_loss_curve.png}
    \caption{WGAN-GP损失曲线}
\end{figure}

从生成的图片来分析，WGAN并没有达到预期的效果，尽管架构相比较普通的GAN有了明显的改进，但最终的效果却
不如朴素的GAN模型。在视觉效果上，WGAN生成的图片基本可以识别数字的种类，但是明显不够清晰，且有较多噪点。
而WGAN-GP在保留了WGAN所有相同的设定的情况下，仅引入了梯度惩罚，就能解决上述问题。

而从损失曲线和wasserstein距离曲线不难看出，GP版本使得训练相当稳定。而且每50个epoch就有一轮大幅的长进，
也恰恰对应了我预先设置的学习率schedule，使得模型在一个阶段学习得差不多后，能够在下个阶段学习更深层次的
特征细节。

以下将从几个角度分析WGAN最终效果差的原因已经GP能够显著改进的原因。

权重裁剪的设置，本实验采用了WGAN原论文的权重裁剪（clip\_value=0.01），但权重裁剪会导致Critic的表达能力受限，容易出现梯度消失或模型容量不足，进而影响生成器的训练效果。

网络结构较为简单,Generator和Critic均为全连接网络，且层数较少，模型容量有限，难以捕捉复杂的数据分布。对于图像生成任务，卷积结构通常更适合，能更好地提取空间特征。

优化器选择与超参数，WGAN原论文使用RMSprop优化器，但本实验中使用Adam也许不适配模型架构。此外，学习率设置过于复杂但是模型过于简单也有可能降低学习效率。

GP的作用在于让判别器的输出更加平滑，不会受到噪声已经误差的影响而突然跳变。
从曲线中不难看出，普通的WGAN曲线在初期十分陡峭且随后波动异常，大概是出现了数值不稳定的情况，进而影响了后续训练，使得效果大打折扣。
打个比方，如果把判别器想象成一条“评分曲线”，原始WGAN用“权重裁剪”让这条曲线变得很“平”，但这样容易让判别器变“笨”，分不清好坏。
而GP就像是在曲线上加了一个“弹簧”，让它既不会太陡峭（防止梯度爆炸），也不会太平（保留判别能力），始终保持适度的弹性。这样生成器和判别器就能更好地互相学习，生成效果也会更好。


\vspace{1cm}
完整的生成图片的样本随epoch的变化在附录


\newpage
\section{任务三：分析GAN在复杂数据集上的性能与模式坍塌问题}
\subsection{实验设置与方法}
任务三采用了BigGAN模型，在ImageNet-1k 数据集上做预训练，并在Animal-Faces上进行微调。
BigGAN是google的Deepmind团队在2019年的一篇工作，是当时GAN系列的sota，在FID和IS两个指标上碾压当时所有的方法，
同时也证明了GAN具有很强的scale性能和较高的上限。

本实验训练了多个版本的BigGAN

\subsection{训练细节与训练技巧}

\subsection{实验结果与分析}

















\newpage
\section{附录}


% ===== GAN 结果展示 =====
\subsection{GAN不同epoch生成的样本}
\vspace{1.5cm}
\begin{figure}[htbp]
    \centering
    \foreach \i/\ep in {1/20,2/40,3/60,4/80,5/100,6/120,7/140,8/160,9/180,10/200} {
        \begin{minipage}[t]{0.23\textwidth}
            \centering
            \includegraphics[width=\textwidth]{/Users/slkgaw/Proj/GANS/visual/GAN/gan_sample_epoch_\ep.png}
            \caption*{GAN \ep~epoch}
        \end{minipage}
        \ifnum\i=4 \par\vspace{0.2cm}\fi
        \ifnum\i=8 \par\vspace{0.2cm}\fi
    }
    \caption{GAN不同epoch生成样本}
    \label{fig:gan_epochs}
\end{figure}


\newpage

% ===== CGAN 结果展示 =====
\subsection{CGAN不同epoch生成的样本}
\vspace{1.5cm}
\begin{figure}[htbp]
    \centering
    \foreach \i/\ep in {1/20,2/40,3/60,4/80,5/100,6/120,7/140,8/160,9/180,10/200} {
        \begin{minipage}[t]{0.23\textwidth}
            \centering
            \includegraphics[width=\textwidth]{/Users/slkgaw/Proj/GANS/visual/CGAN/cgan_sample_epoch_\ep.png}
            \caption*{CGAN \ep~epoch}
        \end{minipage}
        \ifnum\i=4 \par\vspace{0.2cm}\fi
        \ifnum\i=8 \par\vspace{0.2cm}\fi
    }
    \caption{CGAN不同epoch生成样本}
    \label{fig:cgan_epochs}
\end{figure}


\newpage
% ===== WGAN-GP 结果展示 =====
\subsection{WGAN-GP不同epoch生成的样本}
\vspace{1.5cm}
\begin{figure}[htbp]
    \centering
    \foreach \i/\ep in {1/20,2/40,3/60,4/80,5/100,6/120,7/140,8/160,9/180,10/200} {
        \begin{minipage}[t]{0.23\textwidth}
            \centering
            \includegraphics[width=\textwidth]{/Users/slkgaw/Proj/GANS/visual/WGAN-GP//wgan_gp_sample_epoch_\ep.png}
            \caption*{WGAN-GP \ep~epoch}
        \end{minipage}
        \ifnum\i=4 \par\vspace{0.2cm}\fi
        \ifnum\i=8 \par\vspace{0.2cm}\fi
    }
    \caption{WGAN-GP不同epoch生成样本}
    \label{fig:wgan_gp_epochs}
\end{figure}

\newpage
% ==== BigGAN 按类别随机样本 ====
\subsection{BigGAN按类别生成样本展示 128x128}
\begin{center}
\foreach \i in {1,...,7} {
    \includegraphics[width=0.8\textwidth]{/Users/slkgaw/Proj/GANS/visual/BigGAN/128_by_class/\i.jpg}
    \par\vspace{0.1cm}
}
\end{center}
% 每页7张图片，共9页
\foreach \page in {1,...,7} {
    \begin{figure}[htbp]
        \centering
        \foreach \i in {1,...,7} {
            \pgfmathtruncatemacro{\imgnum}{\page*7+\i}
            \ifnum\imgnum<57
                \includegraphics[width=0.8\textwidth]{/Users/slkgaw/Proj/GANS/visual/BigGAN/128_by_class/\imgnum.jpg}
                \par\vspace{0.2cm}
            \fi
        }
        \caption*{BigGAN按类别生成样本（第\the\numexpr\page+1\relax 页）}
    \end{figure}
}

\newpage

\subsection{BigGAN随机样本展示 128x128}
\vspace{1cm}
\begin{center}
\foreach \i in {1,...,3} {
    \includegraphics[width=0.8\textwidth]{/Users/slkgaw/Proj/GANS/visual/BigGAN/128_random/\i.jpg}
    \par\vspace{0.2cm}
}
\end{center}

\foreach \page in {1,...,2} {
    \begin{figure}[htbp]
        \centering
        \foreach \i in {1,...,3} {
            \pgfmathtruncatemacro{\imgnum}{\page*3+\i}
            \ifnum\imgnum<10
                \includegraphics[width=0.8\textwidth]{/Users/slkgaw/Proj/GANS/visual/BigGAN/128_random/\imgnum.jpg}
                \par\vspace{0.2cm}
            \fi
        }
        \caption*{BigGAN随机样本展示（第\the\numexpr\page+1\relax 页）}
    \end{figure}
}

\subsection{BigGAN随机样本展示 512x512}
\vspace{1cm}
\begin{center}
\foreach \i in {1,...,3} {
    \includegraphics[width=0.8\textwidth]{/Users/slkgaw/Proj/GANS/visual/BigGAN/512_random/\i.jpg}
    \par\vspace{0.2cm}
}
\end{center}

\foreach \page in {1} {
    \begin{figure}[htbp]
        \centering
        \foreach \i in {1,...,3} {
            \pgfmathtruncatemacro{\imgnum}{\page*3+\i}
            \ifnum\imgnum<6
                \includegraphics[width=0.8\textwidth]{/Users/slkgaw/Proj/GANS/visual/BigGAN/512_random/\imgnum.jpg}
                \par\vspace{1cm}
            \fi
        }
        \caption*{BigGAN随机样本展示（第\the\numexpr\page+1\relax 页）}
    \end{figure}
}


\subsection{BigGAN不同类别间插值采样}
\vspace{1cm}
\begin{center}
\foreach \i in {1,...,8} {
    \includegraphics[width=0.8\textwidth]{/Users/slkgaw/Proj/GANS/visual/BigGAN/interpolation/\i.png}
    \par\vspace{1cm}
}
\end{center}
\foreach \page in {1,2,3,4} {
    \begin{figure}[htbp]
        \centering
        \foreach \i in {1,...,8} {
            \pgfmathtruncatemacro{\imgnum}{\page*3+\i}
            \ifnum\imgnum<41
                \includegraphics[width=0.8\textwidth]{/Users/slkgaw/Proj/GANS/visual/BigGAN/interpolation/\imgnum.png}
                \par\vspace{1cm}
            \fi
        }
        \caption*{BigGAN不同类别间插值展示（第\the\numexpr\page+1\relax 页）}
    \end{figure}
}


\end{document}

